{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennis - Collaboration and Competition\n",
    "\n",
    "In this project, two agents are trained to play the Tennis tournament. Agents control rackets to bounce the ball over a net. If an agent hits the ball over the net, it receives reward of +0.1 and a reward of -0.01 is given if an agent lets the ball hit the ground or hits the ball out of bounds. Thus goal for both agents is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Each agent receives its own, local observation. Two continous actions are available, corresponding to movement toward (or away from) the net, and jumping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependency Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import player as model\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_environment(env):\n",
    "    '''\n",
    "    Describe the tennis environment\n",
    "    '''\n",
    "    # get the brain\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "    \n",
    "    print('Default Brain: {}, {}'.format(brain_name, brain))\n",
    "   \n",
    "    # reset the environment\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    \n",
    "    # Agents in the environment\n",
    "    print('Active Agents: {}'.format(len(env_info.agents)))\n",
    "    \n",
    "    # Action Space\n",
    "    actions = brain.vector_action_space_size\n",
    "    print('Action Space: {}'.format(actions))\n",
    "    \n",
    "    # State Space\n",
    "    states = env_info.vector_observations\n",
    "    \n",
    "    print('State Space: {}'.format(states.shape[1]))\n",
    "\n",
    "    print('States: {}'.format(states[0]))\n",
    "    \n",
    "    \n",
    "def play_match(env, agent, train = True, matches = 1, max_steps = None):\n",
    "    '''\n",
    "    Play tennis match using given agent and environment\n",
    "    param env: unity tennis environment\n",
    "    param agent: m-dqn agent\n",
    "    param matches: number of matches to play\n",
    "    '''\n",
    "    \n",
    "    total_rewards = 0.\n",
    "    \n",
    "    for i in range(matches):\n",
    "        \n",
    "        step       = 0\n",
    "        rewards    = np.zeros(agent.num_agents)\n",
    "        brain_name = env.brain_names[0]\n",
    "        env_info   = env.reset(train_mode = train)[brain_name]\n",
    "        states     = env_info.vector_observations\n",
    "        \n",
    "        while (max_steps == None) or (j < max_steps):\n",
    "            \n",
    "            # get agent's action for current state\n",
    "            actions = agent.select_actions(states, epsilon = 0., training = train)\n",
    "            \n",
    "            # take the action that agent has selected\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            # get transitioned state and reward\n",
    "            states  = env_info.vector_observations\n",
    "            scores  = env_info.rewards\n",
    "            dones   = env_info.local_done\n",
    "            \n",
    "            rewards += scores\n",
    "            step    += 1\n",
    "            \n",
    "            if any(dones): \n",
    "                break\n",
    "            \n",
    "        total_rewards += np.max(rewards)\n",
    "    \n",
    "    total_rewards /= matches\n",
    "    \n",
    "    print('Avg Score: {:.2f}'.format(total_rewards))\n",
    "    \n",
    "    \n",
    "def plot_rewards(rewards):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(rewards)), rewards)\n",
    "    \n",
    "    plt.ylabel('Reward')\n",
    "    plt.xlabel('Episode')\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show environment details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Brain: TennisBrain, Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n",
      "Active Agents: 2\n",
      "Action Space: 2\n",
      "State Space: 24\n",
      "States: [ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -6.65278625 -1.5        -0.          0.\n",
      "  6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "env = model.get_environment()\n",
    "\n",
    "describe_environment(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the untrained agent and show it's interaction with the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Agent with no training\n",
    "agent = model.get_agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "# navigate the environment with untrained DQN agent\n",
    "play_match(env, agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Agent\n",
    "\n",
    "Training is done in two batches - first 1500 episodes are played and that memory is forwarded for next 1500 play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Episode-100, Eps: 0.9048, Avg Reward: 0.0683\n",
      " Episode-200, Eps: 0.8186, Avg Reward: 0.1203\n",
      " Episode-300, Eps: 0.7407, Avg Reward: 0.1704\n",
      " Episode-400, Eps: 0.6702, Avg Reward: 0.2543\n",
      " Episode-480, Eps: 0.6186, Reward: Avg 0.5032\n",
      " Agents have learned to solve the task. Episode-480, Avg Reward: 0.5032\n",
      " Episode-500, Eps: 0.6064, Avg Reward: 0.7405\n",
      " Episode-516, Eps: 0.5967, Reward: Avg 1.0186\n",
      " Average reward beyond max expectation, stopping training now.\n"
     ]
    }
   ],
   "source": [
    "total_rewards = list()\n",
    "\n",
    "# train the agent in two batches of 1500 each\n",
    "rewards = model.train_players(env, agent, episodes = 1500, max_steps = 2000, share_experience = True)\n",
    "\n",
    "total_rewards = rewards\n",
    "\n",
    "# train the agent for second batch\n",
    "rewards = model.train_players(env, agent, episodes = 1500, max_steps = 2000, share_experience = True)\n",
    "\n",
    "total_rewards += rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent's Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e7b7b32e8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show training for both batches\n",
    "plot_rewards(total_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show navigation of a trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score: 2.60\n"
     ]
    }
   ],
   "source": [
    "model.restore_memory(agent)\n",
    "\n",
    "play_match(env, agent, train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
